{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "This section imports all libraries utilised within the programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Importing necessary libraries for regression models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Importing necessary libraries for splitting data and calculating metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#import Knn from sklearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File importing and preprocessing data\n",
    "This section imports all libraries utilised within the programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    79.99\n",
      "1    61.89\n",
      "2    40.27\n",
      "3    41.05\n",
      "4    44.30\n",
      "Name: csMPa, dtype: float64\n",
      "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
      "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
      "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
      "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
      "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
      "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
      "\n",
      "   fineaggregate    age  \n",
      "0          676.0   28.0  \n",
      "1          676.0   28.0  \n",
      "2          594.0  270.0  \n",
      "3          594.0    NaN  \n",
      "4          825.5  360.0  \n"
     ]
    }
   ],
   "source": [
    "#import data from the files\n",
    "dataset = pd.read_csv('Concrete_Data_Yeh_final.csv')\n",
    "\n",
    "#Data Preprocessing\n",
    "#format as a dataframe\n",
    "dataset = pd.DataFrame(dataset)#\n",
    "#check for null values\n",
    "dataset.isnull().sum()\n",
    "#check for duplicates\n",
    "dataset.duplicated().sum()\n",
    "#check for data types\n",
    "dataset.dtypes\n",
    "\n",
    "y = dataset[\"csMPa\"]\n",
    "X = dataset.drop(\"csMPa\", axis=1)\n",
    "\n",
    "print(y.head()) \n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824, 8)\n",
      "(824,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a preprocessing pipeline that imputes missing values with the mean \n",
    "# and scales features to have zero mean and unit variance.\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Applying the preprocessing steps to the training data and transforming the test data using the same transformations.\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "print(X_train_preprocessed.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression functions\n",
    "\n",
    "This section defines functions for various regression models which are later compared to choose the most effective model.\n",
    "\n",
    "The regression models included are:\n",
    "\n",
    "1. **Linear Regression (`linear_regression`)**: This model assumes a linear relationship between the independent and dependent variables. It is simple and provides interpretable results.\n",
    "\n",
    "2. **Decision Tree Regression (`decision_tree_regression`)**: This model uses a decision tree to predict the dependent variable based on the independent variables. It is a non-parametric method and can capture complex relationships.\n",
    "\n",
    "3. **Random Forest Regression (`random_forest_regression`)**: This model uses a collection of decision trees to make predictions. It is robust to overfitting and can handle large datasets with many variables.\n",
    "\n",
    "4. **Lasso Regression (`lasso_regression`)**: This model is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.\n",
    "\n",
    "5. **Elastic Net Regression (`elastic_net_regression`)**: This model combines the properties of both Ridge Regression and LASSO Regression. It works well on datasets with many features.\n",
    "\n",
    "6. **Ridge Regression (`ridge_regression`)**: This model is a regularization method that uses L2 regularization to prevent overfitting.\n",
    "\n",
    "7. **Support Vector Regression (`svr_regression`)**: This model uses the principles of Support Vector Machines for regression purposes. It works well for datasets with high dimensional space.\n",
    "\n",
    "8. **K-Nearest Neighbors Regression (`knn_regression`)**: This model predicts the value for a new instance by calculating the mean of the 'k' closest instances in the training set.\n",
    "\n",
    "Each function splits the data into a training set and a test set, fits the model to the training data, makes predictions on the test data, and calculates several metrics to evaluate the performance of the model. These metrics include the R2 score, the mean squared error, and the mean absolute error.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "\n",
    "    \"\"\"\n",
    "    This function applies the Linear Regression model to the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray or pandas.DataFrame): The independent variables, i.e., the input for the model.\n",
    "    y (numpy.ndarray or pandas.Series): The dependent variable, i.e., the output for the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The predicted values of the dependent variable for the test set.\n",
    "\n",
    "    Prints:\n",
    "    R2 Score: The coefficient of determination, a statistical measure of how well the regression predictions approximate the real data points.\n",
    "    Mean Squared Error: The average squared difference between the estimated values and the actual value.\n",
    "    Mean Absolute Error: The average absolute difference between the estimated values and the actual value.\n",
    "    \"\"\"\n",
    "    \n",
    "   #Creating the Linear Regression model\n",
    "    regressor = LinearRegression()\n",
    "\n",
    "    # Fitting the data\n",
    "    regressor.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Predicting the data\n",
    "    y_pred = regressor.predict(X_test_preprocessed)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_regression(X, y):\n",
    "    \"\"\"\n",
    "    This function applies the Decision Tree Regression model to the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray or pandas.DataFrame): The independent variables, i.e., the input for the model.\n",
    "    y (numpy.ndarray or pandas.Series): The dependent variable, i.e., the output for the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The predicted values of the dependent variable for the test set.\n",
    "\n",
    "    Prints:\n",
    "    R2 Score: The coefficient of determination, a statistical measure of how well the regression predictions approximate the real data points.\n",
    "    Mean Squared Error: The average squared difference between the estimated values and the actual value.\n",
    "    Mean Absolute Error: The average absolute difference between the estimated values and the actual value.\n",
    "    \"\"\"\n",
    "    # Creating the Decision Tree regressor\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # Fitting the data\n",
    "    regressor.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Predicting the data\n",
    "    y_pred = regressor.predict(X_test_preprocessed)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def random_forest_regression(X, y):\n",
    "    \"\"\"\n",
    "    This function applies the Random Forest Regression model to the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray or pandas.DataFrame): The independent variables, i.e., the input for the model.\n",
    "    y (numpy.ndarray or pandas.Series): The dependent variable, i.e., the output for the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The predicted values of the dependent variable for the test set.\n",
    "\n",
    "    Prints:\n",
    "    R2 Score: The coefficient of determination, a statistical measure of how well the regression predictions approximate the real data points.\n",
    "    Mean Squared Error: The average squared difference between the estimated values and the actual value.\n",
    "    Mean Absolute Error: The average absolute difference between the estimated values and the actual value.\n",
    "    \"\"\"\n",
    "    # Creating the Random Forest Regressor\n",
    "    regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "\n",
    "    # Fitting the data\n",
    "    regressor.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Predicting the data\n",
    "    y_pred = regressor.predict(X_test_preprocessed)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lasso(X, y, alpha=1.0, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Perform Lasso Regression on the given data.\n",
    "\n",
    "    Parameters:\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training data\n",
    "\n",
    "    y : array-like of shape (n_samples,)\n",
    "        Target values\n",
    "\n",
    "    alpha : float, optional (default=1.0)\n",
    "        Constant that multiplies the L1 term. Defaults to 1.0.\n",
    "\n",
    "    test_size : float, optional (default=0.2)\n",
    "        Represents the proportion of the dataset to include in the test split.\n",
    "\n",
    "    random_state : int or RandomState instance, optional (default=None)\n",
    "        Controls the shuffling applied to the data before applying the split.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        Mean squared error of the Lasso model.\n",
    "    \"\"\"\n",
    "    # Create and train the model\n",
    "    model = Lasso(alpha=alpha)\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = model.predict(X_test_preprocessed)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_regression(X, y):\n",
    "    \"\"\"\n",
    "    This function applies the Elastic Net Regression model to the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray or pandas.DataFrame): The independent variables, i.e., the input for the model.\n",
    "    y (numpy.ndarray or pandas.Series): The dependent variable, i.e., the output for the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The predicted values of the dependent variable for the test set.\n",
    "\n",
    "    Prints:\n",
    "    R2 Score: The coefficient of determination, a statistical measure of how well the regression predictions approximate the real data points.\n",
    "    Mean Squared Error: The average squared difference between the estimated values and the actual value.\n",
    "    Mean Absolute Error: The average absolute difference between the estimated values and the actual value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating the Elastic Net Regressor\n",
    "    regressor = ElasticNet(random_state = 0)\n",
    "\n",
    "    # Fitting the data\n",
    "    regressor.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Predicting the data\n",
    "    y_pred = regressor.predict(X_test_preprocessed)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y):\n",
    "    \"\"\"\n",
    "    This function applies the Ridge Regression model to the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray or pandas.DataFrame): The independent variables, i.e., the input for the model.\n",
    "    y (numpy.ndarray or pandas.Series): The dependent variable, i.e., the output for the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The predicted values of the dependent variable for the test set.\n",
    "\n",
    "    Prints:\n",
    "    R2 Score: The coefficient of determination, a statistical measure of how well the regression predictions approximate the real data points.\n",
    "    Mean Squared Error: The average squared difference between the estimated values and the actual value.\n",
    "    Mean Absolute Error: The average absolute difference between the estimated values and the actual value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating the Ridge Regressor\n",
    "    regressor = Ridge(random_state = 0)\n",
    "\n",
    "    # Fitting the data\n",
    "    regressor.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Predicting the data\n",
    "    y_pred = regressor.predict(X_test_preprocessed)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_svr(X, y, kernel='rbf', C=1.0, epsilon=0.1, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Perform Support Vector Regression (SVR) on the given data.\n",
    "\n",
    "    Parameters:\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training data\n",
    "\n",
    "    y : array-like of shape (n_samples,)\n",
    "        Target values\n",
    "\n",
    "    kernel : string, optional (default='rbf')\n",
    "        Specifies the kernel type to be used in the algorithm.\n",
    "        It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or a callable.\n",
    "\n",
    "    C : float, optional (default=1.0)\n",
    "        Regularization parameter. The strength of the regularization is inversely proportional to C.\n",
    "        Must be strictly positive.\n",
    "\n",
    "    epsilon : float, optional (default=0.1)\n",
    "        Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.\n",
    "\n",
    "    test_size : float, optional (default=0.2)\n",
    "        Represents the proportion of the dataset to include in the test split.\n",
    "\n",
    "    random_state : int or RandomState instance, optional (default=None)\n",
    "        Controls the shuffling applied to the data before applying the split.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        Mean squared error of the SVR model.\n",
    "    \"\"\"\n",
    "    # Create and train the model\n",
    "    model = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = model.predict(X_test_preprocessed)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knn(X, y, n_neighbors=5, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Perform K-Nearest Neighbors Regression on the given data.\n",
    "\n",
    "    Parameters:\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training data\n",
    "\n",
    "    y : array-like of shape (n_samples,)\n",
    "        Target values\n",
    "\n",
    "    n_neighbors : int, optional (default=5)\n",
    "        Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "    test_size : float, optional (default=0.2)\n",
    "        Represents the proportion of the dataset to include in the test split.\n",
    "\n",
    "    random_state : int or RandomState instance, optional (default=None)\n",
    "        Controls the shuffling applied to the data before applying the split.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        Mean squared error of the KNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create and train the model\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = model.predict(X_test_preprocessed)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "This section analyses the performance of each regression model to determine which technique most accuratley predicts compressive strength\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelVarTest(dataset):\n",
    "    \"\"\"\n",
    "    This function applies various regression models to each column of the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (pandas.DataFrame): The dataset where each column is treated as a dependent variable in turn, with the other columns serving as independent variables.\n",
    "\n",
    "    Prints:\n",
    "    For each column, the function prints the name of the column, the regression model used, and the performance metrics of the model (R2 Score, Mean Squared Error, Mean Absolute Error).\n",
    "\n",
    "    Note:\n",
    "    The specific regression models used and the way in which the data is split into independent and dependent variables would depend on the implementation within the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Decision Tree Regression': decision_tree_regression(),\n",
    "        'Random Forest Regression': random_forest_regression(),\n",
    "        'Ridge': Ridge(),\n",
    "        'KNN Regression': KNeighborsRegressor(n_neighbors=5),\n",
    "        'Lasso': Lasso(),\n",
    "        'Elastic Net': ElasticNet()\n",
    "            }\n",
    "\n",
    "    # Get the column names\n",
    "    column_names = dataset.columns[:-1]\n",
    "\n",
    "    # Loop over each model\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Testing {model_name}\")\n",
    "\n",
    "        # Loop over each column\n",
    "        for column in column_names:\n",
    "            # Create the features (X) and target (y)\n",
    "            X = dataset[[column]].values\n",
    "            y = dataset.iloc[:, -1].values\n",
    "\n",
    "            # Split the data into training and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Print the R2 score\n",
    "            print(f\"R2 Score for {column}: {r2_score(y_test, y_pred)}\")\n",
    "\n",
    "            # Print the Mean Squared Error\n",
    "            print(f\"Mean Squared Error for {column}: {mean_squared_error(y_test, y_pred)}\")\n",
    "\n",
    "            # Print the Mean Absolute Error\n",
    "            print(f\"Mean Absolute Error for {column}: {mean_absolute_error(y_test, y_pred)}\")\n",
    "\n",
    "# Call the function\n",
    "modelVarTest(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regression models to test\n",
    "models = [LinearRegression(), ElasticNet(), Ridge(), DecisionTreeRegressor(), RandomForestRegressor()]\n",
    "\n",
    "# Generate all combinations of variables\n",
    "for r in range(1, len(X.columns) + 1):\n",
    "    for variables in combinations(X.columns, r):\n",
    "        X_subset = X[list(variables)]\n",
    "\n",
    "        # Fit each model to the data\n",
    "        for model in models:\n",
    "            scores = cross_val_score(model, X_subset, y, cv=5)\n",
    "            print(f'Model: {model.__class__.__name__}, Variables: {variables}, Score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot decision tree y_pred against y_test\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train_preprocessed.shape)\n",
    "\n",
    "y_= random_forest_regression(X_train_preprocessed, y_train)\n",
    "plt.scatter(y_, y_test)\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Actual values\")\n",
    "plt.title(\"Random Forest Regression\")\n",
    "#add a trendline\n",
    "z = np.polyfit(y_, y_test, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_,p(y_), color='red')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6403446787851248\n",
      "Mean Squared Error: 113.40930644412813\n",
      "Mean Absolute Error: 8.695551118340738\n",
      "                                                                           y_pred  \\\n",
      "Model                                                                               \n",
      "Linear Regression               [29.63189345215482, 36.748653951304505, 30.321...   \n",
      "Decision Tree Regression        [48.7, 39.4, 71.3, 35.3, 10.54, 44.28, 23.7, 4...   \n",
      "Random Forest Regression        [50.58919999999996, 40.42360000000006, 72.7301...   \n",
      "Ridge                           [58.82147520978634, 52.05343504212904, 64.2748...   \n",
      "Lasso                           [54.62455468242719, 49.06649048822634, 61.2391...   \n",
      "Elastic Net                     [49.1347262046903, 45.35831614408025, 55.14418...   \n",
      "Support Vector Regression       [41.83374413708075, 53.36749277113666, 55.2966...   \n",
      "K-Nearest Neighbors Regression  [49.010000000000005, 44.14, 63.838, 44.14, 12....   \n",
      "\n",
      "                                     RMSE       R^2        MAE  \n",
      "Model                                                           \n",
      "Linear Regression               21.311520 -0.762598  17.414344  \n",
      "Decision Tree Regression         7.040516  0.807632   4.643107  \n",
      "Random Forest Regression         5.838162  0.867725   4.015103  \n",
      "Ridge                            9.648953  0.638686   7.715769  \n",
      "Lasso                           10.502215  0.571958   8.664118  \n",
      "Elastic Net                     11.175737  0.515296   9.203609  \n",
      "Support Vector Regression        9.560842  0.645255   7.631812  \n",
      "K-Nearest Neighbors Regression   8.628065  0.711098   6.838311  \n",
      "Best model based on sum of ranks: Random Forest Regression\n"
     ]
    }
   ],
   "source": [
    "model_dictionary = [('Linear Regression', linear_regression(X_train_preprocessed, y_train)), \n",
    "                    ('Decision Tree Regression', decision_tree_regression(X_train_preprocessed, y_train)),\n",
    "                    ('Random Forest Regression', random_forest_regression(X_train_preprocessed, y_train)),\n",
    "                    ('Ridge', ridge_regression(X_train_preprocessed, y_train)), \n",
    "                    ('Lasso', perform_lasso(X_train_preprocessed, y_train)), \n",
    "                    ('Elastic Net', elastic_net_regression(X_train_preprocessed, y_train)),\n",
    "                    ('Support Vector Regression', perform_svr(X_train_preprocessed, y_train)),\n",
    "                    ('K-Nearest Neighbors Regression', perform_knn(X_train_preprocessed, y_train))]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model in model_dictionary:\n",
    "    # Predict values for y using X_test_preprocessed\n",
    "    y_pred = model\n",
    "\n",
    "    # Calculate RMSE and R^2 score\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Append the data to the list\n",
    "    data.append([model_name, y_pred, rmse, r2, MAE])\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data, columns=['Model', 'y_pred', 'RMSE', 'R^2','MAE'])\n",
    "\n",
    "# Set the model names as the index\n",
    "df.set_index('Model', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "# Rank each metric, with the highest being the best for R^2 and the lowest being the best for RMSE and MAE\n",
    "df['R^2_rank'] = df['R^2'].rank(ascending=False)\n",
    "df['RMSE_rank'] = df['RMSE'].rank()\n",
    "df['MAE_rank'] = df['MAE'].rank()\n",
    "\n",
    "# Calculate the sum of the ranks\n",
    "df['rank_sum'] = df['R^2_rank'] + df['RMSE_rank'] + df['MAE_rank']\n",
    "\n",
    "# Find the model with the lowest rank sum\n",
    "best_model = df['rank_sum'].idxmin()\n",
    "\n",
    "# Print the best model\n",
    "print(f'Best model based on sum of ranks: {best_model}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
