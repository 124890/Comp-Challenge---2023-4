{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler_Imputer\n",
    "\n",
    "This code fragment was used to test various Scaler-Imputer combinations, along with dropping all rows containing a NaN value. Data is exported to Excel (Scaler_Imputer_Test.XLSX) and the best combination is printed.\n",
    "\n",
    "**Note:** As a group we chose to use the Simple (Mean) Imputer and Standard scaler as we found these were efficient and worked on all regression models during initial testing. As is also shown, there are only marginal improvements when using more complex methods, and the possability of getting much worse values and thus errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# SKLearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, RobustScaler, PowerTransformer, MaxAbsScaler, Binarizer, Normalizer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, learning_curve\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 duplicated rows dropped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import data from the files\n",
    "dataset = pd.read_csv('Concrete_Data_Yeh_final.csv')\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset = dataset.drop_duplicates() #drop duplicates\n",
    "  \n",
    "y = dataset[\"csMPa\"]\n",
    "X = dataset.drop(\"csMPa\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dougl\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scaler:  power_transformer\n",
      "Best imputer:  KNN\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Define the scaler dictionary\n",
    "scaler = {\n",
    "    'standard_scaler': StandardScaler(),\n",
    "    'min_max_scaler': MinMaxScaler(),\n",
    "    'max_abs_scaler': MaxAbsScaler(),\n",
    "    'robust_scaler': RobustScaler(),\n",
    "    'quantile_transformer_normal': QuantileTransformer(n_quantiles=700, output_distribution='normal'),\n",
    "    'quantile_transformer_uniform': QuantileTransformer(n_quantiles=700, output_distribution='uniform'),\n",
    "    'power_transformer': PowerTransformer(),\n",
    "    'normalizer': Normalizer(),\n",
    "    'binarizer': Binarizer()}\n",
    "\n",
    "# Define the imputer dictionary\n",
    "imputer = {'Simple_mean': SimpleImputer(strategy='mean'),\n",
    "              'Simple_median': SimpleImputer(strategy='median'),\n",
    "                'Simple_most_frequent': SimpleImputer(strategy='most_frequent'),\n",
    "                'Simple_constant': SimpleImputer(strategy='constant', fill_value=0),\n",
    "                'Iterative': IterativeImputer(),\n",
    "                'KNN': KNNImputer(),\n",
    "                'MICE': IterativeImputer(initial_strategy='median', imputation_order='random', random_state=0),\n",
    "                'Drop': 'drop'}  # Use 'drop' as a placeholder for droping rows with missing values\n",
    "\n",
    "# Test all combinations of scalers and imputers\n",
    "for imp in imputer:\n",
    "    for scale in scaler:\n",
    "        if imp == 'Drop':\n",
    "            X_transformed = X.dropna()  # Drop rows with missing values\n",
    "            y = y[X_transformed.index]  # Drop corresponding y values\n",
    "        else:\n",
    "            pipeline = Pipeline([\n",
    "                ('imputer', imputer[imp]),\n",
    "                ('scaler', scaler[scale])\n",
    "            ])\n",
    "\n",
    "            X_transformed = pipeline.fit_transform(X)  # Use X produced above\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "        regressor = RandomForestRegressor() # Using the Random Forest Regressor as established as the best performing model previously\n",
    "        regressor.fit(X_train, y_train)\n",
    "        y_pred = regressor.predict(X_test)\n",
    "\n",
    "        #Calculate error metrics and appending to results list\n",
    "        rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        results.append([imp, scale, rmse, r2, mae])\n",
    "\n",
    "#Converting to a dataframe for analysis/ranking and exporting to excel\n",
    "df_results = pd.DataFrame(results, columns=['Imputer', 'Scaler', 'RMSE', 'R2', 'MAE'])\n",
    "df_results['RMSE_rank'] = df_results['RMSE'].rank()\n",
    "df_results['R2_rank'] = df_results['R2'].rank(ascending=False)\n",
    "df_results['MAE_rank'] = df_results['MAE'].rank()\n",
    "df_results['rank_sum'] = df_results['RMSE_rank'] + df_results['R2_rank'] + df_results['MAE_rank']\n",
    "\n",
    "df_results.sort_values(by=['rank_sum'], inplace=True)\n",
    "df_results.to_excel('Scaler_Imputer_Test.xlsx')\n",
    "\n",
    "#Best performing pair of scaler and imputer based on the sum of the ranks\n",
    "best_scaler = df_results['Scaler'].iloc[0]\n",
    "best_imputer = df_results['Imputer'].iloc[0]\n",
    "\n",
    "print('Best scaler: ', best_scaler)\n",
    "print('Best imputer: ', best_imputer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
